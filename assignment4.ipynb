{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Data without NLTK:\n",
      "embarking journey explore diverse landscape culture wonder scattered acros vast planet exhilarating endeavor enriche soul broaden mind traveling world merely physical voyage profound odyssey transcend geographical boundarie transcend cultural difference connect individual universal thread humanity heart globetrotting lie allure discovering new terrain unique charm character awe inspiring peak himalaya serene beache maldive every destination unfold captivating story world become canva painted hue nature lush green jungle arid desert crystal clear lake majestic mountain step brushstroke creating masterpiece memorie linger traveler heart beyond visual feast travel introduce one symphony culture tradition language kaleidoscope diversity every encounter lesson understanding acceptance appreciation sharing meal local italian trattoria immersing oneself vibrant color traditional indian festival listening melodic tone street performer bustling asian market experience form fabric global tapestry woven thread human connection act traveling challenge preconceived notion foster personal growth stepping familiar zone spark sense curiosity resilience one navigate unknown open heart unpredictability travel cultivate adaptability teaching valuable life skill breaking barrier fear prejudice transformative proces akin caterpillar metamorphosing butterfly emerging newfound perspective life traversing world also involve gastronomic journey savoring flavor aroma distinctive region spicy street food southeast asia hearty cuisine south america taste bud become global connoisseur food like universal language connect people fostering camaraderie shared joy communal table destination experience diverse common thread bind every traveler quest self discovery amidst ancient ruin machu picchu dazzling northern light scandinavia amidst bustling street tokyo individual find fragment hidden routine daily life travel become mirror reflecting world innermost aspiration fear dream world often seem divided traveling serve potent reminder interconnectednes emphasize despite difference inhabitant fragile planet witnessing pristine beauty untouched landscape also instill sense responsibility toward environmental conservation traveler become steward advocating sustainable practice cherishing earth natural wonder conclusion journey traveling world saga exploration discovery connection celebration kaleidoscope culture landscape people shape shared human experience odyssey transform itinerary essence traveler leaving indelible mark heart soul let u embrace adventure open mind unknown revel profound joy come traversing diverse wonder world offer\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Read the sample text from the file\n",
    "file_path = 'travelling.txt'  # Replace with your file path\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "\n",
    "# Define a simple stemming function\n",
    "def simple_stem(word):\n",
    "    # You can implement a more sophisticated stemming algorithm if needed\n",
    "    return re.sub(r's$', '', word)\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "# Normalize and stem the words without NLTK\n",
    "stop_words = set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves',\n",
    "                  'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their',\n",
    "                  'theirs', 'themselves', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "                  'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because',\n",
    "                  'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during',\n",
    "                  'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n",
    "                  'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "                  'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can',\n",
    "                  'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn',\n",
    "                  'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn'])\n",
    "normalized_and_stemmed_words = [simple_stem(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "\n",
    "# Save the processed data as a paragraph\n",
    "processed_paragraph = ' '.join(normalized_and_stemmed_words)\n",
    "\n",
    "# Print or save the result as needed\n",
    "print(\"Processed Data without NLTK:\")\n",
    "print(processed_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Text with NLTK:\n",
      "natur languag process nlp is a fascin field that focus on the interact between comput and human use natur languag it involv the develop of algorithm and model to enabl machin to understand interpret and gener humanlik text normal and stem are essenti preprocess step in nlp normal involv convert text to lowercas and remov ani nonalphabet charact stem on the other hand reduc word to their root or base form\n"
     ]
    }
   ],
   "source": [
    "# Function for text normalization and stemming with NLTK\n",
    "def preprocess_text_with_nltk(text):\n",
    "    # Convert to lowercase and remove non-alphabetic characters\n",
    "    normalized_text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
    "\n",
    "    # Use NLTK Porter Stemmer for stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_text = ' '.join([stemmer.stem(word) for word in normalized_text.split()])\n",
    "\n",
    "    return stemmed_text\n",
    "\n",
    "# Preprocess the text with NLTK\n",
    "processed_text_with_nltk = preprocess_text_with_nltk(text)\n",
    "print(\"\\nProcessed Text with NLTK:\")\n",
    "print(processed_text_with_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Data with NLTK:\n",
      "embark journey explor divers landscap cultur wonder scatter across vast planet exhilar endeavor enrich soul broaden mind travel world mere physic voyag profound odyssey transcend geograph boundari transcend cultur differ connect individu univers thread human heart globetrot lie allur discov new terrain uniqu charm charact peak himalaya seren beach maldiv everi destin unfold captiv stori world becom canva paint hue natur lush green jungl arid desert lake majest mountain step brushstrok creat masterpiec memori linger travel heart beyond visual feast travel introduc one symphoni cultur tradit languag kaleidoscop divers everi encount lesson understand accept appreci share meal local italian trattoria immers oneself vibrant color tradit indian festiv listen melod tone street perform bustl asian market experi form fabric global tapestri woven thread human connect act travel challeng preconceiv notion foster person growth step familiar zone spark sens curios resili one navig unknown open heart unpredict travel cultiv adapt teach valuabl life skill break barrier fear prejudic transform process akin caterpillar metamorphos butterfli emerg newfound perspect life travers world also involv gastronom journey savor flavor aroma distinct region spici street food southeast asia hearti cuisin south america tast bud becom global connoisseur food like univers languag connect peopl foster camaraderi share joy commun tabl destin experi divers common thread bind everi travel quest amidst ancient ruin machu picchu dazzl northern light scandinavia amidst bustl street tokyo individu find fragment hidden routin daili life travel becom mirror reflect world innermost aspir fear dream world often seem divid travel serv potent remind interconnected emphas despit differ inhabit fragil planet wit pristin beauti untouch landscap also instil sens respons toward environment conserv travel becom steward advoc sustain practic cherish earth natur wonder conclus journey travel world saga explor discoveri connect celebr kaleidoscop cultur landscap peopl shape share human experi odyssey transform itinerari essenc travel leav indel mark heart soul let us embrac adventur open mind unknown revel profound joy come travers divers wonder world offer\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Read the sample text from the file\n",
    "file_path = 'travelling.txt'  # Replace with your file path\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Tokenize the text into sentences and words\n",
    "sentences = sent_tokenize(text)\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Normalize and stem the words using NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "normalized_and_stemmed_words = [ps.stem(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "\n",
    "# Save the processed data as a paragraph\n",
    "processed_paragraph = ' '.join(normalized_and_stemmed_words)\n",
    "\n",
    "# Print or save the result as needed\n",
    "print(\"Processed Data with NLTK:\")\n",
    "print(processed_paragraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
